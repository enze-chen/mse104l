{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da4c4cef",
   "metadata": {},
   "source": [
    "# Introduction to tabular data in Python\n",
    "\n",
    "*Authors: Enze Chen (University of California, Berkeley)*\n",
    "\n",
    "```{note}\n",
    "This is an interactive exercise, so you will want to click the {fa}`rocket` and open the notebook in DataHub (or Colab for non-UCB students).\n",
    "```\n",
    "\n",
    "This notebook contains a series of exercises that explore tabular data and [the pandas package](https://pandas.pydata.org/).\n",
    "We hope that after going through these exercises, you will be prepared to use pandas and other programmatic tools to operate on tabular data, which can be very helpful when analyzing X-ray diffraction (XRD) data.\n",
    "Like the previous lab, if you're already familiar working with tabular data, you can jump straight to the lab exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff03b23c",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "These exercises are grouped into the following sections:\n",
    "\n",
    "1. [CSVs](#CSV-files)\n",
    "1. [pandas](#pandas!)\n",
    "1. [Operations](#Working-with-DataFrames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e54125d",
   "metadata": {},
   "source": [
    "## CSV files\n",
    "\n",
    "[Back to top](#Contents)\n",
    "\n",
    "By now, you've probably realized that your XRD data is **highly structured**. \n",
    "In particular, it takes the format `angle,intensity` inside a text file, like so:\n",
    "```\n",
    "3.00,1712.5\n",
    "3.02,1850\n",
    "3.04,2075\n",
    "3.06,1912.5\n",
    "...\n",
    "```\n",
    "\n",
    "We call these files **comma-separated values** files, or **CSV** for short.\n",
    "They're nice because they're easy to store and they strike a healthy balance between easy for humans to read (looks like a data table) and easy for computers to read (the values can be loaded into an array).\n",
    "Previously, you've seen how the NumPy package can read in CSV files for plotting purposes.\n",
    "Here, we'll teach you how to use another package that gives you even more flexibility when working with such tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b446ffbe",
   "metadata": {},
   "source": [
    "## pandas!\n",
    "\n",
    "[Back to top](#Contents)\n",
    "\n",
    "![pandas](../assets/fig/pandas.png)\n",
    "\n",
    "[`pandas`](https://pandas.pydata.org/) is Python package developed in 2008 to facilitate data analysis and it has since become one of the most widely used packages in the Python community.\n",
    "The name is derived from \"[panel data](https://en.wikipedia.org/wiki/Panel_data)\" and the package is built on top of [NumPy](https://numpy.org/), which you should already be familiar with!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caef0545",
   "metadata": {},
   "source": [
    "### DataFrames\n",
    "\n",
    "At the heart of pandas lies the [`DataFrame`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) data structure for all of your informatics needs.\n",
    "The DataFrame follows our conventional notion of a spreadsheet for 2D tabular data. \n",
    "Note that a DataFrame is for 2D data **only** and does not work for lower or higher dimensions (unlike NumPy arrays).\n",
    "They feature row and column labels for intelligent indexing and they support **heterogeneously-typed columns**. (a mix of `int`, `str`, `bool`, etc.) üôå\n",
    "\n",
    "To import pandas, the community standard is to use the alias\n",
    "```python\n",
    "import pandas as pd \n",
    "```\n",
    "\n",
    "There are many ways to create DataFrames, but with the [`DataFrame()` constructor](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) you will likely use one of two methods:\n",
    "- `pd.DataFrame(dict)`, where `dict` is a dictionary of `str:list` pairs that correspond to the name and values in each column.\n",
    "- `pd.DataFrame(arr, columns=col_names)`, where `arr` is a 2D NumPy array or list of lists and `col_names` are the names you want to assign each column.\n",
    "\n",
    "You'll likely find yourself using both methods when building DataFrames from scratch, all depends on your use case.\n",
    "Let's see this in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433a46a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Constructor method 1\n",
    "number = [1, 2, 3]\n",
    "mass = [1, 4, 7]\n",
    "df1 = pd.DataFrame({'atomic number':number, 'atomic mass':mass})  # df is common shorthand for DataFrame\n",
    "display(df1)\n",
    "\n",
    "# Constructor method 2\n",
    "arr = [[1, 1], [2, 4], [3, 7]]\n",
    "df2 = pd.DataFrame(arr, columns=['atomic number', 'atomic mass'])\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abf0ffc",
   "metadata": {},
   "source": [
    "And the nice part about working with pandas DataFrames in Jupyter notebooks is the stylistic rendering! üôèüèº\n",
    "Take a moment to see how the column names in the constructors correspond to the names in the DataFrame; in particular, note that these names are labels in the DataFrame, but they're _not_ part of the data itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8383042e",
   "metadata": {},
   "source": [
    "### Reading in a CSV file\n",
    "\n",
    "The above methods are handy, but what if your data source is a CSV file that's already nicely formatted for you?\n",
    "As with our first example in this notebook, it would be nice if we could directly use that structure and express it in Python.\n",
    "You don't want to be stuck typing out all those rows.\n",
    "\n",
    "To do this, we will use the [`pd.read_csv()`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) function which does exactly as the name describes.\n",
    "This function, as you can see from the documentation, has _a bajillion_ input arguments that we don't have time to cover today, so we'll describe just a few here:\n",
    "- `filepath_or_buffer` (str): The only **required** argument, which is the file you're trying to read in.\n",
    "- `sep` (str): The character separating your data tokens. **Default is a comma** (`','`), but you can change this to be space (`' '`), tab (`'\\t'`), etc.\n",
    "- `header` (int): Which row to read column headers from. \n",
    "Default is the first row.\n",
    "- `names` (list): If you would like to rename your columns.\n",
    "This list cannot have duplicates.\n",
    "- `skiprows` (int): Extremely useful if there are extra lines at the top of the file that you want to avoid reading (e.g., comments).\n",
    "- `nrows` (int): Extremely useful if your file is very large or if your data stops before reaching the end of the file (e.g., there's a footer).\n",
    "\n",
    "Notice how this is similar to `np.loadtxt()`, just with a different default separator and some extra headers for the columns (bolded in the previous output). \n",
    "We'll address these headers shortly.\n",
    "\n",
    "------\n",
    "\n",
    "Let's use `pd.read_csv()` to read in our `sine.txt` file from Lab 1's demo (copied again into this folder).\n",
    "We'll also rename the column names to be:\n",
    "```python\n",
    "['x', 'sin']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb8d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sine = pd.read_csv('sine.txt', names=['x', 'sin'])  # try omitting the names argument and see what happens\n",
    "df_sine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf43ff1",
   "metadata": {},
   "source": [
    "## Working with DataFrames\n",
    "\n",
    "[Back to top](#Contents)\n",
    "\n",
    "We got our data into a DataFrame! Now what?\n",
    "\n",
    "_Well, now the fun begins_. üòÑ\n",
    "\n",
    "The first thing you might be interested in is the dimensions of your data (DataFrame).\n",
    "We can access that using the [`df.shape`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html) _attribute_, which returns (rows, columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210334f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sine.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671289cb",
   "metadata": {},
   "source": [
    "We can also get statistics of the rows/columns of the DataFrame by using methods like [`df.min()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.min.html), [`df.max()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.max.html), and [`df.mean()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.mean.html).\n",
    "For these methods, the `axis` parameter specifies if we compute along the columns (`axis=0`) or rows (`1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a71dfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sine.min()   # default is axis=0, compute along columns.\n",
    "                # note these minima are in each INDIVIDUAL column, \n",
    "                # NOT necessarily corresponding to the same data point!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sine.mean(axis=1)    # compute mean along each row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c14b4",
   "metadata": {},
   "source": [
    "### Indexing and slicing a DataFrame\n",
    "\n",
    "There are many ways to [index into a DataFrame](https://pandas.pydata.org/docs/user_guide/indexing.html) and slice it to get subsets of your data.\n",
    "If we want to get the data in particular columns, all you have to do is enter a list of the column names!\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861e8dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sine[['x']]   # this gets the x column of the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845e870d",
   "metadata": {},
   "source": [
    "### Combining columns with operations\n",
    "\n",
    "Recall that with NumPy arrays, we could perform arithmetic operations on the entire array or a slice of it and store the result somewhere.\n",
    "The neat thing about pandas DataFrames is that if we apply an operation to an entire column, we can **store the result in a new column** that's appended to the original DataFrame! \n",
    "The general syntax is:\n",
    "```python\n",
    "df['new_column_name'] = operation(df['old_column_name'])   # note we now have a single string for the column names\n",
    "```\n",
    "See the example below where we use [`np.cos()`](https://numpy.org/doc/stable/reference/generated/numpy.cos.html) to compute the cosine of the `x` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b100de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df_sine['cos'] = np.cos(df_sine['x'])\n",
    "df_sine   # ta-da!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fe1256",
   "metadata": {},
   "source": [
    "Here's another example performing subtraction of one column by another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d644fc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sine['diff (x - sin)'] = df_sine['x'] - df_sine['sin']\n",
    "df_sine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d0566b",
   "metadata": {},
   "source": [
    "Here's yet another example where we simply tack on a new column of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359341d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_sine['foo'] = np.arange(1, df_sine.shape[0] + 1)\n",
    "df_sine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27f614b",
   "metadata": {},
   "source": [
    "### Quick exercise: Add another column to the DataFrame to verify the identity\n",
    "\n",
    "$$ \\sin^{2} + \\cos^{2} = 1 $$\n",
    "\n",
    "Recall that exponentiation is `base ** power`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9e9c9d",
   "metadata": {
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# -------------   WRITE YOUR CODE IN THE SPACE BELOW   ---------- #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35166800",
   "metadata": {},
   "source": [
    "### Plotting data from a DataFrame\n",
    "\n",
    "We can easily index into a DataFrame **using the headers to select the columns** for plotting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dec668",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(df_sine['x'], df_sine['sin'], label='sine')\n",
    "ax.plot(df_sine['x'], df_sine['cos'], label='cosine')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292cf7fa",
   "metadata": {},
   "source": [
    "### Saving a DataFrame\n",
    "\n",
    "There are many ways to save the data, in text, binary, etc., but the easiest way for purely numerical data is probably as a text (CSV) file using [`df.to_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html).\n",
    "Some things to be aware of:\n",
    "- The only required argument is the name of the file.\n",
    "- pandas likes to save the _index_ (row labels) by default, but that looks a little weird if you later open the CSV in a program like Excel, so we typically like to have `index=False`.\n",
    "- Note that this is a method attached to a DataFrame object, not the pandas package! That is, it's `df.to_csv()`, **not** `pd.to_csv(df)`.\n",
    "\n",
    "After you run the following cell, you should see the new file appear in your JupyterHub folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f4361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sine.to_csv('sine_updated.txt', index=False)  # save the df we've been working with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bec3793",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "[Back to top](#Contents)\n",
    "\n",
    "This concludes the introduction to tabular data.\n",
    "Realistically, there's way too much to cover about pandas, and a lot of your understanding will be built as you work with it for your own datasets ([official user guide](https://pandas.pydata.org/docs/user_guide/index.html)).\n",
    "But, we hope that by giving a brief introduction, you at least know what's available, where to go for help, and _how to think about tabular data_ with pandas, at least enough to finish up the lab calculations.\n",
    "Onwards to the exercises!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
